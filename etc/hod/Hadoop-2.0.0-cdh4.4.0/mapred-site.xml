<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<!--
The host and port that the MapReduce job tracker runs at.  If "local", then
jobs are run in-process as a single map and reduce task.
#mapred.job.tracker=:9000
-->
<property>
    <name>mapred.job.tracker</name>
    <value>$masterhostname:8021</value>
</property>

<!--
The local directory where MapReduce stores intermediate data files. May be a
comma-separated list of kindoflist on different devices in order to spread
disk i/o. Directories that do not exist are ignored.
-->
<property>
    <name>mapred.local.dir</name>
    <value></value>
</property>

<!--
As a rule of thumb, use 10x the number of slaves (i.e., number of
TaskTrackers).
-->
<property>
    <name>mapred.map.tasks</name>
    <value></value>
</property>

<!--
As a rule of thumb, use 2x the number of slave processors (i.e., number of
TaskTrackers).
-->
<property>
    <name>mapred.reduce.tasks</name>
    <value></value>
</property>

<!--
The maximum number of map tasks (default is 2)
-->

<property>
    <name>mapred.tasktracker.map.tasks.maximum</name>
    <value></value>
</property>

<!--
The maximum number of map tasks (default is 2)
-->
<property>
    <name>mapred.tasktracker.reduce.tasks.maximum</name>
    <value></value>
</property>

<!--
General java options passed to each task JVM
-->
<property>
    <name>mapred.child.java.opts</name>
    <value>-Xmx1024M</value>
</property>

<!--
Reuse the JVM between tasks If the value is 1 (the default), then JVMs are not
reused (i.e. 1 task per JVM) (-1: no limit)']  # from myhadoop
-->
<property>
    <name>mapred.job.reuse.jvm.num.tasks</name>
    <value>2</value>
</property>

<!--
Fully qualified class name of the task controller class. Currently there are
two implementations of task controller in the Hadoop system,
DefaultTaskController and LinuxTaskController. Refer to the class names
mentioned above to determine the value to set for the class of choice.',
-->
<property>
    <name>mapred.task.tracker.task-controller</name>
    <value></value>
</property>

<!--
If true, then multiple instances of some map tasks may be executed in
parallel.
-->
<property>
    <name>mapred.map.tasks.speculative.exectution</name>
    <value>true</value>
</property>
<!--
If true, then multiple instances of some reduce tasks may be executed in
parallel.
-->
<property>
    <name>mapred.reduce.tasks.speculative.exectution</name>
    <value>true</value>
</property>
<!--
The default number of parallel transfers run by reduce during the
copy(shuffle) phase.
-->
<property>
    <name>mapred.reduce.parallel.copies</name>
    <value>5</value>
</property>

<property>
    <name>mapred.compress.map.output</name>
    <value></value>
</property>

<!--
ACL for InterTrackerProtocol, used by the tasktrackers to communicate with the
jobtracker.
-->
<property>
    <name>security.inter.tracker.protocol.acl</name>
    <value></value>
</property>

<!--
ACL for JobSubmissionProtocol, used by job clients to communciate with the
jobtracker for job submission, querying job status etc.
-->
<property>
    <name>security.job.submission.protocol.acl</name>
    <value></value>
</property>

<!--
ACL for TaskUmbilicalProtocol, used by the map and reduce tasks to communicate
with the parent tasktracker.
-->
<property>
    <name>security.task.umbilical.protocol.acl</name>
    <value></value>
</property>

<!--
A number, in bytes, that represents an offset. The total VMEM on the machine,
minus this offset, is the VMEM node - limit for all tasks, and their
descendants, spawned by the TT.
-->
<property>
    <name>mapred.tasktracker.vmem.reserved</name>
    <value></value>
</property>
<!--
A number, in bytes, that represents the default VMEM task - limit associated
with a task. Unless overridden by a jobs setting, this number defines the VMEM
task-limit.
-->
<property>
    <name>mapred.task.default.maxvmem</name>
    <value></value>
</property>
<!--
A number, in bytes, that represents the upper VMEM task-limit associated with
a task. Users, when specifying a VMEM task-limit for their tasks, should not
specify a limit which exceeds this amount.
-->
<property>
    <name>mapred.task.limit.maxvmem</name>
    <value></value>
</property>
<!--
The time interval, in milliseconds, between which the TT checks for any memory
violation. The default value is 5000 msec (5 seconds).
-->
<property>
    <name>mapred.tasktracker.taskmemorymanager.monitoring-interval</name>
    <value></value>
</property>
<!--
A number, in bytes, that represents an offset. The total physical memory (RAM)
on the machine, minus this offset, is the recommended RAM node-limit. The RAM
node-limit is a hint to a Scheduler to  scheduler only so many tasks such that
the sum total of their RAM requirements does not exceed this limit. RAM usage
is not monitored by a TT.
-->
<property>
    <name>mapred.tasktracker.pmem.reserved</name>
    <value></value>
</property>

<!--
The jobtracker http server address and port the server will listen on. If the
port is 0 then the server will start on a free port.'
-->
<property>
    <name>mapred.job.tracker.http.address</name>
    <value>0.0.0.0:50030</value>
</property>

</configuration>
